-- Step 1: Clear processed_sensor_readings and copy all data from duplicate (excluding generated columns)
TRUNCATE TABLE processed_sensor_readings RESTART IDENTITY CASCADE;

INSERT INTO processed_sensor_readings (
    original_id, recorded_at, location, temperature, humidity, pressure, gas_resistance,
    pm1_0, pm2_5, pm10, accel_x, accel_y, accel_z,
    gyro_x, gyro_y, gyro_z, anomaly_score,
    predicted_failure_probability, quality_score, maintenance_recommendation,
    processing_version, created_at, processed_at, updated_at
)
SELECT 
    original_id, recorded_at, location, temperature, humidity, pressure, gas_resistance,
    pm1_0, pm2_5, pm10, accel_x, accel_y, accel_z,
    gyro_x, gyro_y, gyro_z, anomaly_score,
    predicted_failure_probability, quality_score, maintenance_recommendation,
    processing_version, created_at, processed_at, updated_at
FROM processed_sensor_readings_duplicate;

-- Step 2: Create the new mock_sensor_dataset table structure (with generated columns)
CREATE TABLE mock_sensor_dataset (
    id bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    original_id integer NOT NULL,
    recorded_at timestamp with time zone NOT NULL,
    location text DEFAULT 'hangar_01',
    temperature real,
    humidity real,
    pressure real,
    gas_resistance real,
    pm1_0 integer,
    pm2_5 integer,
    pm10 integer,
    accel_x real,
    accel_y real,
    accel_z real,
    accel_magnitude real GENERATED ALWAYS AS (sqrt(accel_x*accel_x + accel_y*accel_y + accel_z*accel_z)) STORED,
    gyro_x real,
    gyro_y real,
    gyro_z real,
    gyro_magnitude real GENERATED ALWAYS AS (sqrt(gyro_x*gyro_x + gyro_y*gyro_y + gyro_z*gyro_z)) STORED,
    anomaly_score real DEFAULT 0,
    predicted_failure_probability real DEFAULT 0,
    quality_score integer DEFAULT 100,
    processed_at timestamp with time zone DEFAULT now(),
    updated_at timestamp with time zone DEFAULT now(),
    maintenance_recommendation text,
    processing_version text DEFAULT 'v1.0',
    created_at timestamp with time zone DEFAULT now(),
    is_mock_data boolean DEFAULT false
);

-- Step 3: Copy existing data from duplicate to new table (excluding generated columns)
INSERT INTO mock_sensor_dataset (
    original_id, recorded_at, location, temperature, humidity, pressure, gas_resistance,
    pm1_0, pm2_5, pm10, accel_x, accel_y, accel_z,
    gyro_x, gyro_y, gyro_z, anomaly_score,
    predicted_failure_probability, quality_score, maintenance_recommendation,
    processing_version, created_at, processed_at, updated_at,
    is_mock_data
)
SELECT 
    original_id, recorded_at, location, temperature, humidity, pressure, gas_resistance,
    pm1_0, pm2_5, pm10, accel_x, accel_y, accel_z,
    gyro_x, gyro_y, gyro_z, anomaly_score,
    predicted_failure_probability, quality_score, maintenance_recommendation,
    processing_version, created_at, processed_at, updated_at,
    false as is_mock_data
FROM processed_sensor_readings_duplicate;

-- Step 4: Drop the old duplicate table
DROP TABLE processed_sensor_readings_duplicate;

-- Step 5: Enable RLS on the new table
ALTER TABLE mock_sensor_dataset ENABLE ROW LEVEL SECURITY;

-- Step 6: Create RLS policies for the new table
CREATE POLICY "Users can view all mock sensor data" 
ON mock_sensor_dataset 
FOR SELECT 
USING (true);

CREATE POLICY "Authenticated users can insert mock sensor data" 
ON mock_sensor_dataset 
FOR INSERT 
WITH CHECK (auth.uid() IS NOT NULL);

CREATE POLICY "Authenticated users can update mock sensor data" 
ON mock_sensor_dataset 
FOR UPDATE 
USING (auth.uid() IS NOT NULL);